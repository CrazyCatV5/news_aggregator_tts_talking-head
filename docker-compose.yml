name: news_bot

services:
  redis:
    image: redis:7-alpine
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    ports: ["6379:6379"]
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    ports: ["11434:11434"]
    volumes:
      - ollama:/root/.ollama
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]

  ollama-init:
    image: ollama/ollama:latest
    volumes:
      - ollama:/root/.ollama
      - ./scripts/ollama_init.sh:/ollama_init.sh:ro
    environment:
      LLM_MODEL: qwen3:8b
    entrypoint: ["/bin/sh", "/ollama_init.sh"]
    restart: "no"
    depends_on: [ollama]

  llm:
    build: ./services/llm
    ports: ["8099:8099"]
    environment:
      OLLAMA_URL: http://ollama:11434
      LLM_MODEL: qwen3:8b
      LLM_NUM_CTX: "16384"
      LLM_TIMEOUT: "360"
    depends_on: [ollama, ollama-init]
    restart: unless-stopped

  tts:
    build: ./services/tts
    ports: ["8101:8101"]
    environment:
      COQUI_TOS_ACCEPTED: "1"
      TTS_HOME: /data/tts-cache
    volumes:
      - ./data:/data
      - ./data/voices:/data/voices:ro
      - ./tts_out:/data/tts
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: ["gpu"]

  sadtalker:
    build:
      context: ./sadtalker_service
      dockerfile: Dockerfile
    container_name: talking-head-sadtalker
    volumes:
      - ./data:/data
      - ./tts_out:/data/tts
    environment:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    expose: ["8102"]
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: ["gpu"]
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8102/health').read()"]
      interval: 30s
      timeout: 10s
      retries: 3

  api:
    build: ./services/api
    ports: ["8088:8088"]
    environment:
      DB_PATH: /data/app.db
      SOURCES_PATH: /app/sources.json
      USER_AGENT: dfo-news-aggregator/3.0
      REQUEST_TIMEOUT: "25"
      REDIS_URL: redis://redis:6379/0
      FETCH_CONCURRENCY: "16"
      ARTICLE_CONCURRENCY: "32"
      DB_COMMIT_EVERY: "25"
      LLM_SERVICE_URL: http://llm:8099
      TTS_SERVICE_URL: http://tts:8101
      TTS_REF_WAV: /data/voices/ref_clean_g.wav
      TTS_OUT_DIR: /data/tts
      SADTALKER_SERVICE_URL: http://sadtalker:8102
      VIDEO_OUT_DIR: /data/video
      VIDEO_DEFAULT_IMAGE: /data/images/talking_head/default.png
    volumes:
      - ./sources.json:/app/sources.json:ro
      - ./data:/data
      - ./data/voices:/data/voices:ro
      - ./tts_out:/data/tts
    depends_on: [redis, llm, tts]
    restart: unless-stopped

  worker:
    build: ./services/api
    command: ["python", "-m", "app.worker"]
    environment:
      DB_PATH: /data/app.db
      SOURCES_PATH: /app/sources.json
      USER_AGENT: dfo-news-aggregator/3.0
      REQUEST_TIMEOUT: "25"
      REDIS_URL: redis://redis:6379/0
      FETCH_CONCURRENCY: "16"
      ARTICLE_CONCURRENCY: "32"
      DB_COMMIT_EVERY: "25"
    volumes:
      - ./sources.json:/app/sources.json:ro
      - ./data:/data
    depends_on: [redis]
    restart: unless-stopped

  llm_worker:
    build: ./services/api
    command: ["python", "-m", "app.llm_worker"]
    environment:
      DB_PATH: /data/app.db
      REDIS_URL: redis://redis:6379/0
      LLM_SERVICE_URL: http://llm:8099
      LLM_MODEL: qwen3:8b
      LLM_PROMPT_VERSION: v1.0
      LLM_TIMEOUT: "240"
    volumes:
      - ./data:/data
    depends_on: [redis, llm]
    restart: unless-stopped
  tg_bot:
    build: ./tg_bot
    environment:
      TG_API_ID: ${TG_API_ID:-}
      TG_API_HASH: ${TG_API_HASH:-}
      TG_BOT_TOKEN: ${TG_BOT_TOKEN:-}
      TG_ALLOWED_USER_IDS: ${TG_ALLOWED_USER_IDS:-}
      API_BASE_URL: ${API_BASE_URL:-http://api:8088}
      DEFAULT_LANGUAGE: ${DEFAULT_LANGUAGE:-ru}
      TZ: ${TZ:-Europe/Riga}
    depends_on: [api]
    restart: unless-stopped

  scheduler:
    build: ./services/scheduler
    environment:
      API_BASE_URL: ${API_BASE_URL:-http://api:8088}
      TZ: ${TZ:-Europe/Riga}
      INGEST_EVERY_MIN: ${INGEST_EVERY_MIN:-60}
      LLM_EVERY_MIN: ${LLM_EVERY_MIN:-180}
      DAILY_AT: ${DAILY_AT:-08:10}
      RUN_ON_START: ${RUN_ON_START:-0}
    depends_on: [api]
    restart: unless-stopped
volumes:
  ollama:
